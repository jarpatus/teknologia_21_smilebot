import numpy as np
import cv2
import os
import time
from pwmdrive import PWMDrive
from rgbhappy import RGBHappy
from tensorflow.keras import Sequential #for emotion recognition
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array


class Facetrack():

    # Constructor
    def __init__(self):

        # Initialize motors
        self.pwm = PWMDrive()
        self.pwm.stop()
        
        # Initialize RGB matrix
        self.rgb = RGBHappy()
        self.rgb.q()

        # Initialize camera
        self.cap = cv2.VideoCapture(0)
        self.cap.set(3, 640)
        self.cap.set(4, 480)
        
        # Initialize face and emotion recognition 
        self.classifier = load_model('ferjj.h5') # This model has a set of 6 classes
        self.class_labels = {0: 'Angry', 1: 'Fear', 2: 'Happy', 3: 'Neutral', 4: 'Sad', 5: 'Surprise'}
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') 


    # Detects face from given still image (can detect multiple but returns only one)
    def face_detect(self, img):
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        faces = self.face_cascade.detectMultiScale(gray, 1.3, 5)        
        if faces is (): 
            return None, None, None, None, None
        #print(len(faces), "faces detected: ", faces)
        for (x, y, w, h) in faces:
            roi_gray = gray[y:y + h, x:x + w]
        roi_gray = cv2.resize(roi_gray, (48, 48), interpolation=cv2.INTER_AREA)
        return x, w, y, h, roi_gray


    # Detects emotions from given face
    def emotion_detect(self, face):              
        roi = face.astype("float") / 255.0
        roi = img_to_array(roi)
        roi = np.expand_dims(roi, axis=0)
        preds = self.classifier.predict(roi)[0]
        label = self.class_labels[preds.argmax()]
        print(label)
        if label == "Angry": self.rgb.angry()
        elif label == "Fear": self.rgb.fear()
        elif label == "Happy": self.rgb.happy()
        elif label == "Neutral": self.rgb.neutral()
        elif label == "Sad": self.rgb.sad()
        elif label == "Surprise": self.rgb.surprise()
 
 
    def facetrack(self):
        print("Searching...")        
        while True:
        
            # Get still image from camera
            ret, img = self.cap.read()
            
            # Detect face
            #gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            #faces = self.face_cascade.detectMultiScale(
            #    gray,
            #    scaleFactor=1.2,
            #    minNeighbors=5,
            #    minSize=(20,20)
            #)
            x, w, y, h, face = self.face_detect(img)
            if (face is None): 
                #self.pwm.stop()
                continue
            
            # Detect emotion from / rotate towards face
            if x in range(190,270):
                print("Face in range: ", x)
                self.pwm.stop()
                self.emotion_detect(face)
                time.sleep(1)
                self.rgb.q()
            elif x > 240:
                print("Face at right: ", x)                
                #self.pwm.drive(0, 0, 250, 250)
                #self.pwmChangeFrequency(((x-240)*10)^2)
            elif x < 220:
                print("Face at left: ", x)
                #self.pwm.drive(1, 1, 250, 250)
                #self.pwmChangeFrequency(((220-x)*10)^2)    
    
    def stop(self):
        self.pwm.stop()
    
    
if __name__ == "__main__":
    ft = Facetrack()
    try:
        ft.facetrack()
    except Exception as e:
        print(e)
    finally:
        ft.stop()
        